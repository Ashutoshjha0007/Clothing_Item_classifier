{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a786f609-8395-4d5b-93fa-b35fcf808372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the 2nd backup submission from ASHUTOSH JHA from MANIPAL INSTITUTE OF TECHNOLOGY , REGISTRATION NUMBER 210907370 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc277aa-197c-459b-8ebf-1fb5b946e461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: visualkeras in ./.local/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from visualkeras) (9.5.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from visualkeras) (1.23.5)\n",
      "Requirement already satisfied: aggdraw>=1.3.11 in ./.local/lib/python3.9/site-packages (from visualkeras) (1.3.16)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#we need to install necessary packages\n",
    "!pip install visualkeras\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101e901a-4abb-4d0e-8ac6-aeaec93de76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing time libraries for calculating the inferencies\n",
    "import timeit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8d7f06-bf2e-499a-b8c5-9b374146b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot in ./.local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/tensorflow/2.12.0/lib/python3.9/site-packages (from pydot) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b31f756-5381-43c0-81a9-ac7b9762cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 06:20:34.778471: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#importing all other required libraries for building the cnn\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import visualkeras\n",
    "from keras.utils import plot_model\n",
    "import math\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772496f6-a343-4c40-a7a9-5ef2f4f6b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining some parameters beforehand to use them as it is later in code\n",
    "Img_shape = 28\n",
    "Num_classes = 10\n",
    "test_size = 0.25\n",
    "random_state = 1234\n",
    "No_epochs = 45\n",
    "Batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265db5d0-abe7-4745-b734-cea8beb2d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "# IMP NOTE : we need to upload the dataset to our notebook first and then copy paste the path here\n",
    "train_dataset = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test_dataset = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2fee68-ce7e-450f-9392-db4b6b919151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 => T-shirt/top \\n1 => Trouser \\n2 => Pullover \\n3 => Dress \\n4 => Coat \\n5 => Sandal \\n6 => Shirt \\n7 => Sneaker \\n8 => Bag \\n9 => Ankle boot '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining class labels here\n",
    "class_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "'''\n",
    "0 => T-shirt/top \n",
    "1 => Trouser \n",
    "2 => Pullover \n",
    "3 => Dress \n",
    "4 => Coat \n",
    "5 => Sandal \n",
    "6 => Shirt \n",
    "7 => Sneaker \n",
    "8 => Bag \n",
    "9 => Ankle boot '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5b26fc-83cb-4ab2-bc56-226c110a5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data as per the need of our cnn\n",
    "def data_preprocessing(raw):\n",
    "    label = tf.keras.utils.to_categorical(raw.label, 10)\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, 28, 28, 1)\n",
    "    image = x_shaped_array / 255\n",
    "    return image, label\n",
    "\n",
    "X, y = data_preprocessing(train_dataset)\n",
    "X_test, y_test = data_preprocessing(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3cbf29-d377-4a20-8aa7-b2918de3a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855fd4cb-e980-407b-8e89-ad4d8272a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 06:20:50.774101: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    }
   ],
   "source": [
    "#making the cnn architecture from scratch\n",
    "#We are using sequential model which is linear stack of layers. The Sequential model is initialized first and then using add method we add rest of the layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu',kernel_initializer='he_normal', input_shape=(28,28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121594dc-bed9-4235-be36-dec15a9837ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 7, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1152)             4608      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               590336    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 840,586\n",
      "Trainable params: 838,154\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6a9e47-4173-46fd-8727-4aca170effa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=735x150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b4c9e1-2059-4606-a03a-86d694007d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/inteloneapi/tensorflow/latest/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49acb8ff-51ec-462d-b183-4bbeb38def76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "352/352 [==============================] - 174s 492ms/step - loss: 0.5993 - accuracy: 0.7848 - val_loss: 0.4730 - val_accuracy: 0.8202\n",
      "Epoch 2/45\n",
      "352/352 [==============================] - 178s 506ms/step - loss: 0.4033 - accuracy: 0.8511 - val_loss: 0.3774 - val_accuracy: 0.8636\n",
      "Epoch 3/45\n",
      "352/352 [==============================] - 178s 505ms/step - loss: 0.3572 - accuracy: 0.8670 - val_loss: 0.3015 - val_accuracy: 0.8886\n",
      "Epoch 4/45\n",
      "352/352 [==============================] - 177s 504ms/step - loss: 0.3262 - accuracy: 0.8780 - val_loss: 0.2723 - val_accuracy: 0.8987\n",
      "Epoch 5/45\n",
      "352/352 [==============================] - 176s 501ms/step - loss: 0.3063 - accuracy: 0.8848 - val_loss: 0.2774 - val_accuracy: 0.8939\n",
      "Epoch 6/45\n",
      "352/352 [==============================] - 177s 502ms/step - loss: 0.2883 - accuracy: 0.8935 - val_loss: 0.2607 - val_accuracy: 0.9037\n",
      "Epoch 7/45\n",
      "352/352 [==============================] - 177s 503ms/step - loss: 0.2757 - accuracy: 0.8965 - val_loss: 0.2492 - val_accuracy: 0.9080\n",
      "Epoch 8/45\n",
      "352/352 [==============================] - 167s 475ms/step - loss: 0.2600 - accuracy: 0.9036 - val_loss: 0.2513 - val_accuracy: 0.9052\n",
      "Epoch 9/45\n",
      "352/352 [==============================] - 105s 299ms/step - loss: 0.2539 - accuracy: 0.9043 - val_loss: 0.2460 - val_accuracy: 0.9107\n",
      "Epoch 10/45\n",
      "352/352 [==============================] - 105s 297ms/step - loss: 0.2472 - accuracy: 0.9065 - val_loss: 0.2395 - val_accuracy: 0.9093\n",
      "Epoch 11/45\n",
      "352/352 [==============================] - 106s 302ms/step - loss: 0.2425 - accuracy: 0.9090 - val_loss: 0.2196 - val_accuracy: 0.9177\n",
      "Epoch 12/45\n",
      "352/352 [==============================] - 105s 297ms/step - loss: 0.2299 - accuracy: 0.9140 - val_loss: 0.2552 - val_accuracy: 0.9095\n",
      "Epoch 13/45\n",
      "352/352 [==============================] - 103s 292ms/step - loss: 0.2234 - accuracy: 0.9160 - val_loss: 0.2430 - val_accuracy: 0.9125\n",
      "Epoch 14/45\n",
      "352/352 [==============================] - 110s 312ms/step - loss: 0.2200 - accuracy: 0.9166 - val_loss: 0.2411 - val_accuracy: 0.9117\n",
      "Epoch 15/45\n",
      "352/352 [==============================] - 106s 300ms/step - loss: 0.2116 - accuracy: 0.9204 - val_loss: 0.2277 - val_accuracy: 0.9179\n",
      "Epoch 16/45\n",
      "352/352 [==============================] - 101s 286ms/step - loss: 0.2077 - accuracy: 0.9219 - val_loss: 0.2263 - val_accuracy: 0.9215\n",
      "Epoch 17/45\n",
      "352/352 [==============================] - 105s 300ms/step - loss: 0.2067 - accuracy: 0.9225 - val_loss: 0.2218 - val_accuracy: 0.9210\n",
      "Epoch 18/45\n",
      "352/352 [==============================] - 103s 292ms/step - loss: 0.1991 - accuracy: 0.9254 - val_loss: 0.2294 - val_accuracy: 0.9155\n",
      "Epoch 19/45\n",
      "352/352 [==============================] - 103s 292ms/step - loss: 0.1989 - accuracy: 0.9248 - val_loss: 0.2088 - val_accuracy: 0.9256\n",
      "Epoch 20/45\n",
      "352/352 [==============================] - 103s 292ms/step - loss: 0.1912 - accuracy: 0.9288 - val_loss: 0.2107 - val_accuracy: 0.9229\n",
      "Epoch 21/45\n",
      "352/352 [==============================] - 99s 282ms/step - loss: 0.1865 - accuracy: 0.9299 - val_loss: 0.2051 - val_accuracy: 0.9262\n",
      "Epoch 22/45\n",
      "352/352 [==============================] - 102s 290ms/step - loss: 0.1812 - accuracy: 0.9322 - val_loss: 0.2074 - val_accuracy: 0.9251\n",
      "Epoch 23/45\n",
      "352/352 [==============================] - 104s 294ms/step - loss: 0.1774 - accuracy: 0.9324 - val_loss: 0.2100 - val_accuracy: 0.9238\n",
      "Epoch 24/45\n",
      "352/352 [==============================] - 106s 300ms/step - loss: 0.1793 - accuracy: 0.9318 - val_loss: 0.2064 - val_accuracy: 0.9259\n",
      "Epoch 25/45\n",
      "352/352 [==============================] - 106s 303ms/step - loss: 0.1697 - accuracy: 0.9365 - val_loss: 0.2070 - val_accuracy: 0.9264\n",
      "Epoch 26/45\n",
      "352/352 [==============================] - 105s 299ms/step - loss: 0.1697 - accuracy: 0.9360 - val_loss: 0.2020 - val_accuracy: 0.9279\n",
      "Epoch 27/45\n",
      "352/352 [==============================] - 105s 298ms/step - loss: 0.1674 - accuracy: 0.9360 - val_loss: 0.2151 - val_accuracy: 0.9253\n",
      "Epoch 28/45\n",
      "352/352 [==============================] - 102s 290ms/step - loss: 0.1665 - accuracy: 0.9382 - val_loss: 0.2090 - val_accuracy: 0.9272\n",
      "Epoch 29/45\n",
      "352/352 [==============================] - 102s 291ms/step - loss: 0.1620 - accuracy: 0.9402 - val_loss: 0.2087 - val_accuracy: 0.9275\n",
      "Epoch 30/45\n",
      "352/352 [==============================] - 105s 299ms/step - loss: 0.1546 - accuracy: 0.9419 - val_loss: 0.2172 - val_accuracy: 0.9245\n",
      "Epoch 31/45\n",
      "352/352 [==============================] - 104s 297ms/step - loss: 0.1611 - accuracy: 0.9398 - val_loss: 0.2043 - val_accuracy: 0.9300\n",
      "Epoch 32/45\n",
      "352/352 [==============================] - 104s 295ms/step - loss: 0.1565 - accuracy: 0.9400 - val_loss: 0.2132 - val_accuracy: 0.9251\n",
      "Epoch 33/45\n",
      "352/352 [==============================] - 105s 298ms/step - loss: 0.1578 - accuracy: 0.9409 - val_loss: 0.2038 - val_accuracy: 0.9266\n",
      "Epoch 34/45\n",
      "352/352 [==============================] - 104s 295ms/step - loss: 0.1503 - accuracy: 0.9439 - val_loss: 0.2060 - val_accuracy: 0.9312\n",
      "Epoch 35/45\n",
      "352/352 [==============================] - 107s 304ms/step - loss: 0.1449 - accuracy: 0.9450 - val_loss: 0.2051 - val_accuracy: 0.9295\n",
      "Epoch 36/45\n",
      "352/352 [==============================] - 102s 291ms/step - loss: 0.1463 - accuracy: 0.9442 - val_loss: 0.2055 - val_accuracy: 0.9266\n",
      "Epoch 37/45\n",
      "352/352 [==============================] - 101s 287ms/step - loss: 0.1453 - accuracy: 0.9447 - val_loss: 0.2082 - val_accuracy: 0.9309\n",
      "Epoch 38/45\n",
      "352/352 [==============================] - 102s 289ms/step - loss: 0.1389 - accuracy: 0.9480 - val_loss: 0.1959 - val_accuracy: 0.9316\n",
      "Epoch 39/45\n",
      "352/352 [==============================] - 107s 304ms/step - loss: 0.1392 - accuracy: 0.9476 - val_loss: 0.2246 - val_accuracy: 0.9249\n",
      "Epoch 40/45\n",
      "352/352 [==============================] - 102s 289ms/step - loss: 0.1389 - accuracy: 0.9476 - val_loss: 0.2069 - val_accuracy: 0.9298\n",
      "Epoch 41/45\n",
      "352/352 [==============================] - 107s 304ms/step - loss: 0.1358 - accuracy: 0.9489 - val_loss: 0.2041 - val_accuracy: 0.9298\n",
      "Epoch 42/45\n",
      "352/352 [==============================] - 106s 300ms/step - loss: 0.1317 - accuracy: 0.9504 - val_loss: 0.2029 - val_accuracy: 0.9327\n",
      "Epoch 43/45\n",
      "352/352 [==============================] - 105s 297ms/step - loss: 0.1322 - accuracy: 0.9501 - val_loss: 0.2016 - val_accuracy: 0.9289\n",
      "Epoch 44/45\n",
      "352/352 [==============================] - 105s 298ms/step - loss: 0.1312 - accuracy: 0.9511 - val_loss: 0.2129 - val_accuracy: 0.9271\n",
      "Epoch 45/45\n",
      "352/352 [==============================] - 102s 290ms/step - loss: 0.1253 - accuracy: 0.9529 - val_loss: 0.2231 - val_accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=Batch_size,\n",
    "                  epochs=No_epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72576bda-89f6-4996-a40b-3ade5d93a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6ea73d-1ea8-4d50-8348-e37b85b8c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image for inference\n",
    "sample_input = X_train[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736a112a-7fa3-4a8a-9b25-3b455aa065f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n"
     ]
    }
   ],
   "source": [
    "# Warm up the model\n",
    "_ = model.predict(sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42100242-73b4-4495-8b95-928b4f532916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of iterations for measurement\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec280423-026b-4cc7-a37c-7fdffd46eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the inference and measure the time\n",
    "def inference_time():\n",
    "    _ = model.predict(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c57a0734-1c68-4be7-afd3-025d909fe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# Measure the inference time\n",
    "elapsed_time = timeit.timeit(inference_time, number=num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb55ad9-1fca-46d6-aa57-827f7884ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized Baseline inference latency: 0.0808745653508231 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average inference time per iteration\n",
    "average_latency = elapsed_time / num_iterations\n",
    "\n",
    "print(f\"optimized Baseline inference latency: {average_latency} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aae6bd81-9a52-4815-8dfc-5f8dfe6c3c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2142 - accuracy: 0.9274\n",
      "Test loss: 0.21421955525875092\n",
      "optimised Test accuracy: 0.9273999929428101\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, steps=math.ceil(10000/32))\n",
    "# checking the test loss and test accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('optimised Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61928099-2729-4fc3-ae30-10c2e2ca91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd67551b-e5a4-4da4-b590-2f34a8551456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image for inference\n",
    "sample_input = X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "989224eb-71aa-46f7-862e-577547de11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# Warm up the model\n",
    "_ = model.predict(sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b853d68a-d777-464f-812a-b2a17e823269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of iterations for measurement\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6856dd55-a1ac-45ea-bac6-9715165974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the inference and measure the time\n",
    "def inference_time():\n",
    "    _ = model.predict(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa573c68-2334-42dc-b362-ce46fc01b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Measure the inference time\n",
    "elapsed_time = timeit.timeit(inference_time, number=num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3b99d83-598c-43bb-91b0-4d8a25cd6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u=Un-optimized Baseline inference latency: 0.08754627275047824 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average inference time per iteration\n",
    "average_latency = elapsed_time / num_iterations\n",
    "\n",
    "print(f\"u=Un-optimized Baseline inference latency: {average_latency} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da70fcdc-ab36-472d-b6af-5d7702e3d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2142 - accuracy: 0.9274\n",
      "Test loss: 0.21421955525875092\n",
      "Un-optimised Test accuracy: 0.9273999929428101\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, steps=math.ceil(10000/32))\n",
    "# checking the test loss and test accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Un-optimised Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1613b38-5eb8-4463-9529-b2cee6cd3b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2142 - accuracy: 0.9274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21421955525875092, 0.9273999929428101]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.round(2)\n",
    " \n",
    "y_test\n",
    " \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "981025bf-0f1e-4fcb-9f4e-016142d38104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('2ndbackup_fashion_mnist_cnn_model.h5') # Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c3c61a0-7f0e-4c3f-b5ff-494a9d613377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_cnn_model = tf.keras.models.load_model('2ndbackup_fashion_mnist_cnn_model.h5')\n",
    " \n",
    "Y_pred_sample = fashion_mnist_cnn_model.predict(np.expand_dims(X_test[0], axis=0)).round(2)\n",
    "Y_pred_sample\n",
    " \n",
    "np.argmax(Y_pred_sample[0])\n",
    " \n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21052e9a-444d-4f21-8614-b056e3efc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flollowing code is for converting the .h5 format to IR format for openvino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0baa5dd-64cc-403a-9ba1-67c723554936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger(\"openvino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a257c371-8f28-4ac2-830d-d15959b9de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-14 07:48:55--  https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
      "Resolving apt.repos.intel.com (apt.repos.intel.com)... 104.68.99.13, 2600:1406:cc00:28a::4b23, 2600:1406:cc00:28d::4b23\n",
      "Connecting to apt.repos.intel.com (apt.repos.intel.com)|104.68.99.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 939 [binary/octet-stream]\n",
      "Saving to: GPG-PUB-KEY-INTEL-OPENVINO-2021.4\n",
      "\n",
      "GPG-PUB-KEY-INTEL-O 100%[===================>]     939  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-14 07:48:55 (82.0 MB/s) - GPG-PUB-KEY-INTEL-OPENVINO-2021.4 saved [939/939]\n",
      "\n",
      "Dear User,\n",
      "\n",
      "this server does not allow you to run \"sudo\".\n",
      "\n",
      "If you need to install a dependency, please put it in your home directory.\n",
      "* For autotools, you can do it with \"./configure --prefix=~/my-path\"\n",
      "* For Python packages, use \"pip install <package_name> --user\" or create a Conda environment.\n",
      "\n",
      "Sincerely,\n",
      "Admins\n",
      "u194070 is not in the sudoers file.  This incident will be reported.\n",
      "Dear User,\n",
      "\n",
      "this server does not allow you to run \"sudo\".\n",
      "\n",
      "If you need to install a dependency, please put it in your home directory.\n",
      "* For autotools, you can do it with \"./configure --prefix=~/my-path\"\n",
      "* For Python packages, use \"pip install <package_name> --user\" or create a Conda environment.\n",
      "\n",
      "Sincerely,\n",
      "Admins\n",
      "u194070 is not in the sudoers file.  This incident will be reported.\n",
      "Dear User,\n",
      "\n",
      "this server does not allow you to run \"sudo\".\n",
      "\n",
      "If you need to install a dependency, please put it in your home directory.\n",
      "* For autotools, you can do it with \"./configure --prefix=~/my-path\"\n",
      "* For Python packages, use \"pip install <package_name> --user\" or create a Conda environment.\n",
      "\n",
      "Sincerely,\n",
      "Admins\n",
      "Dear User,\n",
      "\n",
      "this server does not allow you to run \"sudo\".\n",
      "\n",
      "If you need to install a dependency, please put it in your home directory.\n",
      "* For autotools, you can do it with \"./configure --prefix=~/my-path\"\n",
      "* For Python packages, use \"pip install <package_name> --user\" or create a Conda environment.\n",
      "\n",
      "Sincerely,\n",
      "Admins\n",
      "bash: /opt/intel/openvino_2021/bin/setupvars.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wget https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
    "!sudo apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
    "!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | sudo tee /etc/apt/sources.list.d/intel-openvino-2021.list\n",
    "!sudo apt update > /dev/null $2>&1\n",
    "!sudo apt install intel-openvino-dev-ubuntu20-2021.3.394 -y > /dev/null $2>&1\n",
    "!bash /opt/intel/openvino_2021/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bf284cc-1436-4eeb-906a-ee9b82ba812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openvino-dev in ./.local/lib/python3.9/site-packages (2023.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino-dev) (6.0)\n",
      "Requirement already satisfied: addict>=2.4.0 in ./.local/lib/python3.9/site-packages (from openvino-dev) (2.4.0)\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.9/site-packages (from openvino-dev) (4.8.0.74)\n",
      "Requirement already satisfied: texttable>=1.6.3 in ./.local/lib/python3.9/site-packages (from openvino-dev) (1.6.7)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino-dev) (1.23.5)\n",
      "Requirement already satisfied: networkx<=3.1 in ./.local/lib/python3.9/site-packages (from openvino-dev) (2.8.8)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in ./.local/lib/python3.9/site-packages (from openvino-dev) (0.7.1)\n",
      "Requirement already satisfied: scipy>=1.8 in ./.local/lib/python3.9/site-packages (from openvino-dev) (1.11.1)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino-dev) (4.64.0)\n",
      "Requirement already satisfied: openvino-telemetry>=2022.1.0 in ./.local/lib/python3.9/site-packages (from openvino-dev) (2023.0.0)\n",
      "Requirement already satisfied: pillow>=8.1.2 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino-dev) (9.5.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino-dev) (2.28.1)\n",
      "Requirement already satisfied: jstyleson>=0.0.2 in ./.local/lib/python3.9/site-packages (from openvino-dev) (0.0.2)\n",
      "Requirement already satisfied: openvino==2023.0.1 in ./.local/lib/python3.9/site-packages (from openvino-dev) (2023.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.25.1->openvino-dev) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install openvino-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e72da522-8af9-47be-afa7-e64241945381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 07:49:00.439695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-14 07:49:00.456502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,3,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-14 07:49:00.471071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-14 07:49:00.773556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-14 07:49:00.837613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,3,3,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-14 07:49:00.903192: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"2ndbackup_fashion_mnist_cnn_model.h5\")\n",
    "tf.saved_model.save(model,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d17da794-3e37-473b-bfb2-c0697e175ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 7, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1152)             4608      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               590336    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 840,586\n",
      "Trainable params: 838,154\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "conv2d (None, 28, 28, 1)\n",
      "dense_1 dense_1/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(model.layers[0].name, model.layers[0].get_input_shape_at(0))\n",
    "print(model.layers[-1].name, model.layers[-1].get_output_at(0).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b27c512-a1f1-4a8d-b310-ccb04d9e3003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openvino in ./.local/lib/python3.9/site-packages (2023.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from openvino) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c13407f2-1c60-4a84-b666-7632374db63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried it at its almost working but showing minute error in new devices as the location of directory might not be same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21a62ae7-a95f-404e-8324-353abf40c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/home/u194070/openvino/model-optimizer/mo_tf.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python3 openvino/model-optimizer/mo_tf.py --2ndbackup_fashion_mnist_cnn_model.h5 --input_shape=\\[1,28,28\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d27a9fdf-25fb-48fc-a084-c965c2b50de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *.h5 *.xml *.bin *.mapping model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe34a9-f69b-4455-8c4f-27c819b3256b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
